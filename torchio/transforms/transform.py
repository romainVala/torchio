import numbers
import warnings
from typing import Union
from copy import deepcopy
from abc import ABC, abstractmethod

import torch
import numpy as np
import SimpleITK as sitk

from .. import TypeData, INTENSITY, DATA
from ..data.image import Image
from ..data.subject import Subject
from ..data.dataset import ImagesDataset
from ..utils import nib_to_sitk, sitk_to_nib
import numpy as np
import time
from .interpolation import Interpolation


class Transform(ABC):
    """Abstract class for all TorchIO transforms.

    All classes used to transform a sample from an
    :py:class:`~torchio.ImagesDataset` should subclass it.
    All subclasses should overwrite
    :py:meth:`torchio.tranforms.Transform.apply_transform`,
    which takes a sample, applies some transformation and returns the result.

    Args:
        p: Probability that this transform will be applied.
    """

    def __init__(self, p: float = 1, verbose: bool = False, compare_to_original: bool = False, metrics: dict = None):
        self.probability = self.parse_probability(p)
        self.verbose = verbose
        self.compare_to_original = compare_to_original
        self.metrics = metrics

    def __call__(self, data: Union[Subject, torch.Tensor, np.ndarray]):
        """Transform a sample and return the result.

        Args:
            data: Instance of :py:class:`~torchio.Subject`, 4D
                :py:class:`torch.Tensor` or 4D NumPy array with dimensions
                :math:`(C, D, H, W)`, where :math:`C` is the number of channels
                and :math:`D, H, W` are the spatial dimensions. If the input is
                a tensor, the affine matrix is an identity and a tensor will be
                also returned.
        """
        if torch.rand(1).item() > self.probability:
            return data
        if isinstance(data, (np.ndarray, torch.Tensor)):
            is_array = isinstance(data, np.ndarray)
            is_tensor = True
            sample = self.parse_tensor(data)
        elif isinstance(data, list):
            return [self.__call__(ii) for ii in data]
        else:
            is_tensor = is_array = False
            sample = data

        if self.verbose:
            start = time.time()

        self.parse_sample(sample)

        # If the input is a tensor, it will be deepcopied when calling
        # ImagesDataset.__getitem__
        orig = sample
        if not is_tensor:
            sample = deepcopy(sample)

        with np.errstate(all='raise'):
            transformed = self.apply_transform(sample)

        # Compute the metrics after the transformation
        if self.compare_to_original and self.metrics:
            _ = [metric_func(orig, transformed) for metric_func in self.metrics.values()]

        if self.verbose:
            duration = time.time() - start
            print(f'{self.__class__.__name__}: {duration:.3f} seconds')

        if is_tensor:
            num_channels = len(data)
            images = [
                transformed[f'channel_{i}'][DATA]
                for i in range(num_channels)
            ]
            transformed = torch.cat(images)
        if is_array:
            transformed = transformed.numpy()
        return transformed

    @abstractmethod
    def apply_transform(self, sample: Subject):
        raise NotImplementedError

    @staticmethod
    def parse_probability(probability: float) -> float:
        is_number = isinstance(probability, numbers.Number)
        if not (is_number and 0 <= probability <= 1):
            message = (
                'Probability must be a number in [0, 1],'
                f' not {probability}'
            )
            raise ValueError(message)
        return probability

    @staticmethod
    def parse_sample(sample: Subject) -> None:
        if not isinstance(sample, Subject):
            message = (
                'Input to a transform must be a PyTorch tensor or an instance'
                ' of torchio.Subject generated by a torchio.ImagesDataset,'
                f' not "{type(sample)}"'
            )
            raise RuntimeError(message)

    def parse_tensor(self, data: TypeData) -> Subject:
        if isinstance(data, np.ndarray):
            tensor = torch.from_numpy(data)
        else:
            tensor = data
        tensor = tensor.float()  # does nothing if already float
        num_dimensions = tensor.dim()
        if num_dimensions != 4:
            message = (
                'The input tensor must have 4 dimensions (channels, i, j, k),'
                f' but has {num_dimensions}: {tensor.shape}'
            )
            raise RuntimeError(message)
        return self._get_subject_from_tensor(tensor)

    @staticmethod
    def parse_interpolation(interpolation: str) -> Interpolation:
        if isinstance(interpolation, Interpolation):
            message = (
                'Interpolation of type torchio.Interpolation'
                ' is deprecated, please use a string instead'
            )
            warnings.warn(message, FutureWarning)
        elif isinstance(interpolation, str):
            interpolation = interpolation.lower()
            supported_values = [key.name.lower() for key in Interpolation]
            if interpolation in supported_values:
                interpolation = getattr(Interpolation, interpolation.upper())
            else:
                message = (
                    f'Interpolation "{interpolation}" is not among'
                    f' the supported values: {supported_values}'
                )
                raise AttributeError(message)
        else:
            message = (
                'image_interpolation must be a string,'
                f' not {type(interpolation)}'
            )
            raise TypeError(message)
        return interpolation

    @staticmethod
    def _get_subject_from_tensor(tensor: torch.Tensor) -> Subject:
        subject_dict = {}
        for channel_index, channel_tensor in enumerate(tensor):
            name = f'channel_{channel_index}'
            image = Image(tensor=channel_tensor, type=INTENSITY)
            subject_dict[name] = image
        subject = Subject(subject_dict)
        dataset = ImagesDataset([subject])
        sample = dataset[0]
        return sample

    @staticmethod
    def nib_to_sitk(data: TypeData, affine: TypeData):
        return nib_to_sitk(data, affine)

    @staticmethod
    def sitk_to_nib(image: sitk.Image):
        return sitk_to_nib(image)

    @staticmethod
    def _fft_im(image):
        output = (np.fft.fftshift(np.fft.fftn(np.fft.ifftshift(image)))).astype(np.complex128)
        return output

    @staticmethod
    def _ifft_im(freq_domain):
        output = np.fft.ifftshift(np.fft.ifftn(freq_domain))
        return output

    @staticmethod
    def _oversample(data, perc_oversampling=.10, padding_mode='constant', padding_normal=None):
        """
        Oversamples data with a zero padding. Adds perc_oversampling percentage values
        :param data (ndarray): array to pad
        :param perc_oversampling (float): percentage of oversampling to add to data (based on its current shape)
        :return oversampled version of the data:
        """
        data_shape = list(data.shape)
        to_pad = np.ceil(np.asarray(data_shape) * perc_oversampling / 2) * 2
        # to force an even number if odd, this will shift the volume when croping
        # print("Pading at {}".format(to_pad))
        left_pad = np.floor(to_pad / 2).astype(int)
        right_pad = np.ceil(to_pad / 2).astype(int)

        if padding_mode == "random.normal":
            pad_data = np.pad(data, list(zip(left_pad, right_pad)))
            data_shape = list(pad_data.shape)

            # replace the padding values by random nois
            size_pad = left_pad[0] * data_shape[1] * data_shape[2]
            pad_data[:left_pad[0], :, :] = np.random.normal(padding_normal[0], padding_normal[1],
                                                            size_pad).reshape(left_pad[0], data_shape[1], data_shape[2])

            size_pad = left_pad[1] * data_shape[0] * data_shape[2]
            pad_data[:, :left_pad[1], :] = np.random.normal(padding_normal[0], padding_normal[1],
                                                            size_pad).reshape(data_shape[0], left_pad[1], data_shape[2])

            size_pad = left_pad[2] * data_shape[1] * data_shape[0]
            pad_data[:, :, :left_pad[2]] = np.random.normal(padding_normal[0], padding_normal[1],
                                                            size_pad).reshape(data_shape[0], data_shape[1], left_pad[2])

            size_pad = right_pad[0] * data_shape[1] * data_shape[2]
            pad_data[-right_pad[0]:, :, :] = np.random.normal(padding_normal[0], padding_normal[1],
                                                              size_pad).reshape(right_pad[0], data_shape[1],
                                                                                data_shape[2])

            size_pad = right_pad[1] * data_shape[0] * data_shape[2]
            pad_data[:, -right_pad[1]:, :] = np.random.normal(padding_normal[0], padding_normal[1],
                                                              size_pad).reshape(data_shape[0], right_pad[1],
                                                                                data_shape[2])

            size_pad = right_pad[2] * data_shape[1] * data_shape[0]
            pad_data[:, :, -right_pad[0]:] = np.random.normal(padding_normal[0], padding_normal[1],
                                                              size_pad).reshape(data_shape[0], data_shape[1],
                                                                                right_pad[2])
            # print('PADING with random nois {} {}'.format(padding_normal[0], padding_normal[1]))
        else:
            pad_data = np.pad(data, list(zip(left_pad, right_pad)), mode=padding_mode)

        return pad_data

    @staticmethod
    def crop_volume(data, cropping_shape):
        '''
        Cropping data to cropping_shape size. Cropping starts from center of the image
        '''
        vol_centers = (np.asarray(data.shape) / 2).astype(int)
        dim_ranges = np.ceil(np.asarray(cropping_shape) / 2).astype(int)
        slicing = [slice(dim_center - dim_range, dim_center + dim_range)
                   for dim_center, dim_range in zip(vol_centers, dim_ranges)]
        return data[tuple(slicing)]

    @property
    def name(self):
        return self.__class__.__name__
